{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Week 7 - Final Project DTSA5509\"\n",
        "author: \"James Clulow\"\n",
        "format: html\n",
        "editor: visual\n",
        "jupyter: python3\n",
        "bibliography: inst/references/references.bib\n",
        "csl: inst/references/apa-numeric-superscript-brackets.csl\n",
        "toc: true\n",
        "toc-location: left\n",
        "toc-expand: true\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: setup-libraries\n",
        "\n",
        "## Setup and library import\n",
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import joblib\n",
        "\n",
        "from keras.applications.vgg16 import VGG16\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn import preprocessing\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, RocCurveDisplay\n",
        "from IPython.display import Markdown, display"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: support-functions\n",
        "\n",
        "# Support functions\n",
        "def unzip_data_raw(data_raw_pth):\n",
        "    # Function to unzip raw data\n",
        "    zip_path = 'inst/data_raw.zip'\n",
        "    data_raw_path = data_raw_pth\n",
        "    # Check if data_raw.zip exists in inst folder\n",
        "    if not os.path.exists(zip_path):\n",
        "        return \"Error: data_raw.zip does not exist in the inst folder.\"\n",
        "    # Overwrite the data_raw folder if it already exists\n",
        "    if os.path.exists(data_raw_path):\n",
        "        shutil.rmtree(data_raw_path)\n",
        "\n",
        "    # Extract the zip file to data_raw folder\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(data_raw_path)\n",
        "        \n",
        "    return \"Raw data unzipped successfully.\"\n",
        "\n",
        "def count_files_per_directory(path):\n",
        "    # Create a dictionary to store folder names and their corresponding file counts\n",
        "    file_count = {}\n",
        "\n",
        "    # Walk through the directory\n",
        "    for root, dirs, files in os.walk(path):\n",
        "        # Get the last part of the directory path (the subdirectory name)\n",
        "        subdirectory_name = os.path.basename(root)\n",
        "\n",
        "        # Count files in the current directory\n",
        "        if root != path:  # Skip the root directory\n",
        "            file_count[subdirectory_name] = len(files)\n",
        "\n",
        "    # Convert the dictionary to a DataFrame for better visualization\n",
        "    df = pd.DataFrame(list(file_count.items()), \n",
        "                      columns=['Subdirectory Name', 'Number of Files'])\n",
        "    \n",
        "    # Display the DataFrame\n",
        "    return print(df)\n",
        "    \n",
        "def create_training_labels_csv(raw_path, out_path):   \n",
        "    # Check if data_raw path exists\n",
        "    if not os.path.exists(raw_path):\n",
        "        return \"Error: data_raw directory does not exist.\"\n",
        "    \n",
        "    # Create data directory and overwrite if already exists\n",
        "    os.makedirs(out_path, exist_ok=True)\n",
        "\n",
        "    # Create a list to store paths and labels\n",
        "    labels = []\n",
        "\n",
        "    # Walk through the directory\n",
        "    for root, dirs, files in os.walk(raw_path):\n",
        "        # Get the label from the directory name (subdirectory)\n",
        "        label = os.path.basename(root)\n",
        "        # Iterate over each file in the current directory\n",
        "        for file in files:\n",
        "            # Construct the full file path\n",
        "            file_path = os.path.join(root, \n",
        "                                     file)\n",
        "            # Append the file path and label to the labels list\n",
        "            labels.append((file_path, \n",
        "                           label))\n",
        "\n",
        "    # Convert the list to a DataFrame for better visualization\n",
        "    df = pd.DataFrame(labels, columns=['image_path', \n",
        "                                       'label'])\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    train_df, test_df = train_test_split(df, \n",
        "                                         test_size=0.2, \n",
        "                                         stratify=df['label'], \n",
        "                                         random_state=42)\n",
        "    \n",
        "    # Define the output CSV file paths\n",
        "    output_train_csv_path = os.path.join(out_path, 'training_labels.csv')\n",
        "    output_test_csv_path = os.path.join(out_path, 'testing_labels.csv')\n",
        "\n",
        "    # Export the DataFrames to CSV files\n",
        "    train_df.to_csv(output_train_csv_path, index=False)\n",
        "    test_df.to_csv(output_test_csv_path, index=False)\n",
        "\n",
        "    # Print the paths of the saved CSV files\n",
        "    print(f'Training DataFrame exported to: {output_train_csv_path}')\n",
        "    print(f'Testing DataFrame exported to: {output_test_csv_path}')\n",
        "\n",
        "    return(train_df, test_df)\n",
        "\n",
        "def copy_files_to_label_subdirectories(df, target_directory):\n",
        "    # Iterate through each row in the DataFrame\n",
        "    for index, row in df.iterrows():\n",
        "        image_path = row['image_path']\n",
        "        label = row['label']\n",
        "\n",
        "        # Create the target subdirectory path\n",
        "        label_directory = (target_directory + '/' + label)\n",
        "        \n",
        "        # Create the directory if it doesn't exist\n",
        "        os.makedirs(label_directory, exist_ok=True)\n",
        "\n",
        "        # Copy the file to the corresponding label subdirectory\n",
        "        try:\n",
        "            if os.path.exists(label_directory):\n",
        "                shutil.copy(image_path, label_directory)\n",
        "        except Exception as e:\n",
        "            print(f'Error copying {image_path} to {label_directory}: {e}')\n",
        "\n",
        "def create_image_and_label_arrays(df):\n",
        "    # Function that loads images, resizes them, and converts images and lables to np.arrays\n",
        "    images = [] # Init images list\n",
        "    for img_path in df['image_path']:\n",
        "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)       \n",
        "        img = cv2.resize(img, (img_height, img_width))\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "        images.append(img)\n",
        "    \n",
        "    # Convert to np.array\n",
        "    images_array, labels_array = np.array(images), np.array(df['label'])\n",
        "    return images_array, labels_array\n",
        "\n",
        "def result_random_img(model, X_test, test_labels, feature_extractor, le):\n",
        "    # Check results using a random image\n",
        "    mdl = model\n",
        "    n = np.random.randint(0, X_test.shape[0])\n",
        "    img = X_test[n]\n",
        "\n",
        "    input_img = np.expand_dims(img, axis=0) # Expand dims so the input is (num images, x, y, c)\n",
        "    input_img_feature = feature_extractor.predict(input_img)\n",
        "    input_img_features = input_img_feature.reshape(input_img_feature.shape[0], -1)\n",
        "    pred = mdl.predict(input_img_features)[0] \n",
        "    pred = le.inverse_transform([pred])  # Reverse the label encoder to original name\n",
        "    print(\"The prediction for this image is: \", pred[0])\n",
        "    print(\"The actual label for this image is: \", test_labels[n])\n",
        "    plt.imshow(img)\n",
        "\n",
        "def plot_confusion_matrix(model, y_true, y_pred, le):\n",
        "    mdl = model\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=le.inverse_transform(mdl.classes_))\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                              display_labels=le.inverse_transform(mdl.classes_))\n",
        "    disp.plot()\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.title(f\"Confusion Matrix for {model.__class__.__name__}\")\n",
        "    plt.show()\n",
        "\n",
        "def compare_classification_reports(list_of_models, y_test, X_test):\n",
        "    reports = []\n",
        "    \n",
        "    for model in list_of_models:\n",
        "        y_pred = model.predict(X_test)\n",
        "        report = classification_report(y_test, y_pred, output_dict=True)\n",
        "        report_df = pd.DataFrame(report).transpose()\n",
        "        report_df['model'] = model.__class__.__name__\n",
        "        reports.append(report_df)\n",
        "    \n",
        "    comparison_df = pd.concat(reports)\n",
        "    comparison_df.reset_index(inplace=True)\n",
        "    comparison_df.rename(columns={'index': 'metric'}, inplace=True)\n",
        "    \n",
        "    return comparison_df\n",
        "\n",
        "def plot_ROC_for_all(list_of_models, y_train, y_test, X_test):\n",
        "    label_binarizer = preprocessing.LabelBinarizer().fit(y_train)\n",
        "    y_onehot_test = label_binarizer.transform(y_test)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    \n",
        "    for i, model in enumerate(list_of_models):\n",
        "        y_score = model.predict_proba(X_test)\n",
        "        display = RocCurveDisplay.from_predictions(\n",
        "            y_onehot_test.ravel(),\n",
        "            y_score.ravel(),\n",
        "            name=f\"micro-average OvR for {model.__class__.__name__}\",\n",
        "            plot_chance_level=(i == len(list_of_models) - 1),\n",
        "            ax=plt.gca()\n",
        "            )\n",
        "\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.title(\"Micro-averaged One-vs-Rest\\nReceiver Operating Characteristic for All Models\")\n",
        "    plt.legend(loc=\"best\")\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DTSA5509 Introduction to Machine Learning: Supervised Learning - Final Project\n",
        "\n",
        "## Introduction and Problem Description\n",
        "\n",
        "This Quarto notebook is for my final project for DTSA-5509 Introduction to Machine Learning: Supervised Learning. All of the required dependencies for this notebook are listed above in the setup cell. Please make sure you have the required packages installed to run the notebook.\n",
        "\n",
        "For my project, I wanted to look at a machine learning problem focusing on computer vision. I work in the coffee industry and an important problem in the industry is the reliable grading of green coffees (unroasted coffee). Arabica green coffee is graded by taking a sample of 300g and counting the number of visual defects in a sample. Additionally, a standardized roasting protocol is applied and sensory evaluation (cupping) is performed to detect any sensory defects in addition to any visual defects.\n",
        "\n",
        "There are multiple classes of visual defect and the process has been standardized by the [Specialty Coffee Association (SCA)](https://sca.coffee/) and the [Coffee Quality Institute (CQI)](https://www.coffeeinstitute.org/).\n",
        "\n",
        "The SCA method @spe2017washed for grading green arabica coffee breaks down coffee quality into 5 classes:\n",
        "\n",
        "-   **Specialty Grade Green Coffee (1):** Specialty green coffee beans have no more than 5 full defects in 300 grams of coffee. No primary defects are allowed. A maximum of 5% above or below screen size indicated is tolerated. Specialty coffee must possess at least one distinctive attribute in the body, flavor, aroma, or acidity. Must be free of faults and taints. No quakers are permitted. Moisture content is between 9-13%.\n",
        "\n",
        "-   **Premium Coffee Grade (2):** Premium coffee must have no more than 8 full defects in 300 grams. Primary defects are permitted. A maximum of 5% above or below screen size indicated is tolerated. Must possess at least one distinctive attribute in the body, flavor, aroma, or acidity. Must be free of faults and may contain only 3 quakers. Moisture content is between 9-13%.\n",
        "\n",
        "-   **Exchange Coffee Grade (3):** Exchange grade coffee must have no more than 9-23 full defects in 300 grams. It must be 50% by weight above screen size 15 with no more than 5% of screen size below 14. No cup faults are permitted and a maximum of 5 quakers are allowed. Moisture content is between 9-13%.\n",
        "\n",
        "-   **Below Standard Coffee Grade (4):** 24-86 defects in 300 grams.\n",
        "\n",
        "-   **Off Grade Coffee (5):** More than 86 defects in 300 grams.\n",
        "\n",
        "Coffee defects are broken down into **intrinsic defects** and **extrinsic defects**. **Intrinsic defects** are inherent to the beans themselves (i.e. full sour/full black), whereas **extrinsic defects** are related to the sample and not the beans (i.e. presence of foreign matter - stones or sticks in a sample). Defects are also classed as **primary** and **secondary** defects. In the SCA grading method, **primary defects** are penalized more than **secondary defects** due to the nature of the defects. @tbl-primary_defects and @tbl-secondary_defects below summarize primary and secondary defects [@Carpenter_2021; @Griffin_2006].\n",
        "\n",
        "| Primary Defect | Number of occurrences equal to one full defect |\n",
        "|----------------|------------------------------------------------|\n",
        "| Full Black     | 1                                              |\n",
        "| Full Sour      | 1                                              |\n",
        "| Pod/Cherry     | 1                                              |\n",
        "| Large Stones   | 2                                              |\n",
        "| Medium Stones  | 5                                              |\n",
        "| Large Sticks   | 2                                              |\n",
        "| Medium Sticks  | 5                                              |\n",
        "\n",
        ": Primary Defects as described by the SCA green coffee grading method. {#tbl-primary_defects}\n",
        "\n",
        "| Secondary Defect | Number of occurrences equal to one full defect |\n",
        "|------------------|------------------------------------------------|\n",
        "| Parchment        | 2-3                                            |\n",
        "| Hull/Husk        | 2-3                                            |\n",
        "| Broken/Chipped   | 5                                              |\n",
        "| Insect Damage    | 2-5                                            |\n",
        "| Partial Black    | 2-3                                            |\n",
        "| Partial Sour     | 2-3                                            |\n",
        "| Floater          | 5                                              |\n",
        "| Shell            | 5                                              |\n",
        "| Small Stones     | 1                                              |\n",
        "| Small Sticks     | 1                                              |\n",
        "| Water Damage     | 2-5                                            |\n",
        "\n",
        ": Secondary Defects as described by the SCA green coffee grading method. {#tbl-secondary_defects}\n",
        "\n",
        "As this is a classification problem, a machine learning model and computer vision system could (in theory) be reliably trained to complete the visual grading task saving a significant amount of time for green coffee graders. In December 2024, a team from Thailand recently published a paper in the Journal of Smart Agricultural Technology using a convolution neural network (CNN) to classify defects in arabica beans from Thailand @ARWATCHANANUKUL2024100680 . They made their [dataset](https://www.kaggle.com/datasets/sujitraarw/coffee-green-bean-with-17-defects-original) available to the public on Kaggle @Arwatchananukul_2024 . While CNNs are best suited to this type of data, there is a case for using a pre-trained CNN for feature extraction followed by other classification techniques such as those we covered in DTSA5509 @https://doi.org/10.1155/2022/2013181. I wanted to apply and evaluate the performance of the following three supervised learning techniques that were covered in DTSA5509:\n",
        "\n",
        "1.  KNN Classification\n",
        "\n",
        "2.  Random Forest Classification\n",
        "\n",
        "3.  XGBoost Classification\n",
        "\n",
        "They breakdown the defects into more classes than those used by the SCA grading system. In total there are 17 classes as shown in the image below:\n",
        "\n",
        "![Green coffee defect classes in the dataset - Taken from @ARWATCHANANUKUL2024100680](img/defect_classes.jpg)\n",
        "\n",
        "## Image Pre-processing and Loading\n",
        "\n",
        "For the image pre-processing, first we start by unzipping the raw data files from `inst/data_raw.zip` to `data_raw`. Then we create a 80/20 train/test split of the files in a new directory 'data'. The information on the train/test split is stored in the `data\\training_labels.csv` and `data\\testing_labels.csv` files. Finally, we output a count of all files in the original dataset for each defect class as well as the counts for all files in the train/test datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: extract-pre-processing\n",
        "\n",
        "# Create path variables\n",
        "data_raw_pth = 'data_raw'\n",
        "data_pth = 'data'\n",
        "test_path = 'data/test'\n",
        "train_path = 'data/train'\n",
        "\n",
        "# Unzip data_raw.zip\n",
        "unzip_data_raw(data_raw_pth)\n",
        "\n",
        "# Create training_labels.csv\n",
        "train_df, test_df = create_training_labels_csv(data_raw_pth, out_path = data_pth)\n",
        "\n",
        "# Copy files to train\n",
        "copy_files_to_label_subdirectories(train_df, train_path)  \n",
        "\n",
        "# Copy files to test\n",
        "copy_files_to_label_subdirectories(test_df, test_path)\n",
        "\n",
        "# Return counts per directory for all classes/subdirectories\n",
        "count_files_per_directory(data_raw_pth)\n",
        "count_files_per_directory(train_path)\n",
        "count_files_per_directory(test_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we load images and resize them to 256x256 pixels (down from 512x512) to save on memory. Labels are loaded and encoded to integers instead of strings for use in the model. Pixel values from the images are normalized to values between 0 and 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: load-images\n",
        "\n",
        "# Define parameters for image loading/resizing\n",
        "img_height = 256\n",
        "img_width = 256\n",
        "\n",
        "# Load images and create arrays for test and train sets.     \n",
        "train_images, train_labels = create_image_and_label_arrays(train_df)          \n",
        "test_images, test_labels = create_image_and_label_arrays(test_df)\n",
        "\n",
        "# Encode labels from text to integers\n",
        "label_enc = preprocessing.LabelEncoder()\n",
        "label_enc.fit(test_labels)\n",
        "test_labels_enc = label_enc.transform(test_labels)\n",
        "label_enc.fit(train_labels)\n",
        "train_labels_enc = label_enc.transform(train_labels)\n",
        "\n",
        "# Normalize pixel values to between 0 and 1\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "# Assign test and train datasets to conventional variable names\n",
        "X_train, y_train, X_test, y_test = train_images, train_labels_enc, test_images, test_labels_enc\n",
        "y_true = test_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After loading the images we test by plotting a random image with its label to be sure that we have loaded the images and labels correctly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: randimg-check\n",
        "#| fig-cap: \"Random Image with Label to check loading\"\n",
        "\n",
        "# Check a random image to make sure that loading has worked correctly \n",
        "n = np.random.randint(0, X_test.shape[0])\n",
        "img = X_test[n]\n",
        "plt.imshow(img)\n",
        "print(\"The label for this image is: \", test_labels[n])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## High Level Feature Extraction using a Pre-trained model\n",
        "\n",
        "To conduct image analysis on the coffee dataset, I chose to use a pre-trained convolution neural network to extract high level features for training KNN, Random Forest, and XGBoost classifier models. I used a [VGG16 model](https://keras.io/api/applications/vgg/) with pre-trained weights from [ImageNet](https://www.image-net.org/) available through the [Keras API](https://keras.io). I load a pre-trained VGG16 model that is non-trainable to work only using the pre-trained weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: setup-pretrained-featext\n",
        "\n",
        "# Setup pretrained model using imagenet weights\n",
        "# Load pretrained model without classifier/fully connected layers\n",
        "vgg_mdl = VGG16(weights='imagenet', \n",
        "include_top=False, \n",
        "input_shape=(img_height, img_width, 3))\n",
        "\n",
        "# Make the loaded layers non-trainable to ensure we work only with pre-trained weights\n",
        "for layer in vgg_mdl.layers:\n",
        "\tlayer.trainable = False\n",
        "\n",
        "vgg_mdl.summary()  # Trainable parameters will be 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once the VGG16 model has been loaded, we can use it as a feature extractor to create our `classifier_X_train` and `classifier_X_test` datasets that will be used to train the classification models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: extract-train-features\n",
        "\n",
        "# Extract features from pretrained CNN on training set\n",
        "extracted_features = vgg_mdl.predict(X_train)\n",
        "\n",
        "# Reshape to create X_train for the classifier (KNN, RF, GradientBoosting)\n",
        "classifier_X_train = extracted_features.reshape(extracted_features.shape[0], -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: extract-test-features\n",
        "\n",
        "### Extract features from pretrained CNN on test set\n",
        "extracted_test_features = vgg_mdl.predict(X_test)\n",
        "\n",
        "# Reshape to create X_test for the classifier (KNN, RF, GradientBoosting)\n",
        "classifier_X_test = extracted_test_features.reshape(extracted_test_features.shape[0], -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Classification Models\n",
        "\n",
        "Now that the features have been extracted using the VGG16 pre-trained model and the data reshaped to create the `classifier_X_train` and `classifier_X_test` datasets, we can start to train and optimise our classification models.\n",
        "\n",
        "### K-Nearest Neighbours Classifier\n",
        "\n",
        "I start by training a KNN classifier and optimise the number of neighbours screening values between 1 and 30 using 5 fold cross validation and accuracy as a metric. This is done using the code shown below (I will spare you the computational effort to run it)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: optimise-knn_model\n",
        "#| eval: false\n",
        "#| echo: true\n",
        "\n",
        "# Train KNN Model and optimise n_neighbors using cross_val_score\n",
        "k_values = np.arange(1, 31)\n",
        "scores = []\n",
        "\n",
        "for k in k_values:\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    score = cross_val_score(knn, classifier_X_train, y_train, cv=5, scoring = 'accuracy')\n",
        "    scores.append(np.mean(score))\n",
        "\n",
        "# Plot Accuracy vs k Neighbours\n",
        "plt.plot(k_values, scores)  \n",
        "plt.xlabel('k neighbours')\n",
        "plt.ylabel('Accuracy score')  \n",
        "plt.title('Accuracy score vs k neighbours for KNN Model') \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![KNN Accuracy vs. k_neighbours](img/knn_accuracy_neighbours.png)\n",
        "\n",
        "The resulting plot shows that the highest accuracy achieved during the cross validation is with a k of 6. So we use 6 as the number of neighbors for the final model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: train-knn_model\n",
        "\n",
        "# Train optimized KNN model\n",
        "knn_model = KNeighborsClassifier(n_neighbors = 6)\n",
        "knn_model.fit(classifier_X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Random Forest Classifier\n",
        "\n",
        "Next we start by training a Random Forest classifier and optimizing on the number of estimators to use. The code used for the optimization is shown below, but I will spare you the computational effort to run it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: optimise-rf_model\n",
        "#| eval: false\n",
        "#| echo: true\n",
        "\n",
        "# Train Random Forest Model and optimise n_estimators using accuracy score\n",
        "n_values = np.arange(100, 1700, 100)\n",
        "scores = []\n",
        "\n",
        "for n in n_values:\n",
        "    rf = RandomForestClassifier(n_estimators=n, max_depth=60, random_state=42, bootstrap = False)\n",
        "    score = cross_val_score(rf, classifier_X_train, y_train, cv=3, scoring = 'accuracy')\n",
        "    scores.append(np.mean(score))\n",
        "\n",
        "# Plot Accuracy vs n estimators\n",
        "plt.plot(n_values, scores)  \n",
        "plt.xlabel('n estimators')\n",
        "plt.ylabel('Accuracy score')  \n",
        "plt.title('Accuracy score vs n estimators for Random Forest Model') \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The optimal value for the number of estimators is 400 and achieves the highest accuracy as shown in the plot below. The final model is trained on 400 learners.\n",
        "\n",
        "![Random Forest Accuracy vs. n_learners](img/rf_accuracy_nlearners.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: train-rf_model\n",
        "\n",
        "# Train optimized Random Forest Model\n",
        "rf_model = RandomForestClassifier(n_estimators = 400, max_depth=60, random_state=42, bootstrap = False)\n",
        "rf_model.fit(classifier_X_train, y_train)\n",
        "rf_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### XGBoost Classifier\n",
        "\n",
        "Finally, I trained an XGBoost classifier using the histogram tree method using the code below and exported the trained model to file using `joblib`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: train-xgboost_model\n",
        "#| eval: false\n",
        "#| echo: true\n",
        "\n",
        "# Train XGBoost Model\n",
        "xgboost_model = xgb.XGBClassifier(tree_method=\"hist\")\n",
        "xgboost_model.fit(classifier_X_train, y_train)\n",
        "\n",
        "joblib.dump(xgboost_model, 'inst/xgboost_model.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I exported the saved model using `joblib` to facilitate the evaluation of this notebook as it is time consuming train the model. I opted not to perform cross validation on this model as it took a significant amount of time to train on my laptop which has limited RAM and computing power. Below, we load the trained model from the `.pkl` file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: load-xgboost_model\n",
        "\n",
        "# Load trained XGBoost Model\n",
        "xgboost_model = joblib.load('inst/xgboost_model.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Performance Metrics\n",
        "\n",
        "To evaluate the performance of each model, we will look at the classification report summary and micro-averaged One-vs-Rest ROC AUC score as metrics. I also plot a confusion matrix for each model as well as plotting a random image with its true label and predicted label.\n",
        "\n",
        "### K-Nearest Neighbours Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: classification_report-knn_model\n",
        "#| warning: false\n",
        "\n",
        "# Test model performance\n",
        "y_pred_tf = knn_model.predict(classifier_X_test)\n",
        "y_pred = label_enc.inverse_transform(y_pred_tf)\n",
        "y_score = knn_model.predict_proba(classifier_X_test)\n",
        "\n",
        "print(classification_report(y_true, y_pred))\n",
        "\n",
        "micro_roc_auc_ovr = roc_auc_score(\n",
        "    y_true,\n",
        "    y_score,\n",
        "    multi_class=\"ovr\",\n",
        "    average=\"micro\"\n",
        ")\n",
        "\n",
        "print(f\"Micro-averaged One-vs-Rest ROC AUC score:\\n{micro_roc_auc_ovr:.2f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The full classification report for KNN model shows an overall accuracy of 0.48 which is not very good. The ROC AUC is 0.83 which is not great either. Several classes have poor precision using this model and it leaves much to be desired."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: cm-knn_model\n",
        "#| fig-cap: \"Confusion Matrix for KNN Model\"\n",
        "\n",
        "# Plot Confusion Matrix for KNN Model\n",
        "plot_confusion_matrix(knn_model, y_true=y_true, y_pred=y_pred, le = label_enc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Looking at the confusion matrix, we can see that some classes have decent performance i.e. \"Husk\", \"Full Black\", \"Parchment\", but others have poor performance, such as the \"Withered\" class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: randimg-KNN_model\n",
        "#| fig-cap: \"Random Image with Label and Prediction using KNN Model\"\n",
        "\n",
        "# Check the results of a random image with the KNN model\n",
        "result_random_img(knn_model, X_test=X_test, test_labels= y_true, feature_extractor=vgg_mdl, le=label_enc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The random image above shows its true label and the predicted label using the KNN model.\n",
        "\n",
        "### Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: classification_report-rf_model\n",
        "\n",
        "# Test model performance\n",
        "y_pred_tf = rf_model.predict(classifier_X_test)\n",
        "y_pred = label_enc.inverse_transform(y_pred_tf)\n",
        "y_score = rf_model.predict_proba(classifier_X_test)\n",
        "\n",
        "print(classification_report(y_true, y_pred))\n",
        "\n",
        "micro_roc_auc_ovr = roc_auc_score(\n",
        "    y_true,\n",
        "    y_score,\n",
        "    multi_class=\"ovr\",\n",
        "    average=\"micro\"\n",
        ")\n",
        "\n",
        "print(f\"Micro-averaged One-vs-Rest ROC AUC score:\\n{micro_roc_auc_ovr:.2f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The full classification report for Random Forest model shows an overall accuracy of 0.65 which is OK considering that we are using a pre-trained CNN for the feature extraction. The ROC AUC is 0.97 which is actually quite good, but could be further improved. There are a few classes (\"Withered\", \"Insect Damage\", and \"Fade\") have poor precision using this model and it could potentially be improved with further hyperparameter tuning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: cm-rf_model\n",
        "#| fig-cap: \"Confusion Matrix for Random Forest Model\"\n",
        "\n",
        "# Plot Confusion Matrix for Random Forest Model\n",
        "plot_confusion_matrix(rf_model, y_true=y_true, y_pred=y_pred, le = label_enc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Looking at the confusion matrix, we can see that the Random Forest model has decent performance across the majority of classes, but struggles with a few classes in particular."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: randimg-rf_model\n",
        "#| fig-cap: \"Random Image with Label and Prediction using RF Model\"\n",
        "\n",
        "# Check results using a random image with the Random Forest Model\n",
        "result_random_img(rf_model, X_test=X_test, test_labels= y_true, feature_extractor=vgg_mdl, le=label_enc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The random image above shows its true label and the predicted label using the Random Forest model.\n",
        "\n",
        "### XGBoost Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: classification_report-xgboost_model\n",
        "\n",
        "# Test model performance\n",
        "y_pred_tf = xgboost_model.predict(classifier_X_test)\n",
        "y_pred = label_enc.inverse_transform(y_pred_tf)\n",
        "y_score = xgboost_model.predict_proba(classifier_X_test)\n",
        "\n",
        "print(classification_report(y_true, y_pred))\n",
        "\n",
        "micro_roc_auc_ovr = roc_auc_score(\n",
        "    y_true,\n",
        "    y_score,\n",
        "    multi_class=\"ovr\",\n",
        "    average=\"micro\"\n",
        ")\n",
        "\n",
        "print(f\"Micro-averaged One-vs-Rest ROC AUC score:\\n{micro_roc_auc_ovr:.2f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The full classification report for XGBoost model shows an overall accuracy of 0.709 which is quite good considering that we are using a pre-trained CNN for the feature extraction. The ROC AUC is 0.97 which is good by most standards. There are a few classes (i.e. \"Fade\" and \"Slight Insect Damage\") that have low precision using this model. However, model has quite good precision on the majority of classes with a weighted average of close to 73%. Nevertheless, the model could potentially be improved with further hyperparameter tuning (which I did not do as a result of the the time to fit this model on my mediocre laptop)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: cm-xgboost_model\n",
        "#| fig-cap: \"Confusion Matrix for xgboost Model\"\n",
        "\n",
        "# Plot Confusion Matrix for XGBoost Model\n",
        "plot_confusion_matrix(xgboost_model, y_true=y_true, y_pred=y_pred, le = label_enc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Looking at the confusion matrix, we can see that the XGBoost model has good performance across the majority of classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: randimg-xgboost_model\n",
        "#| fig-cap: \"Random Image with Label and Prediction using xgboost Model\"\n",
        "\n",
        "# Check results on a random image with the xgboost model\n",
        "result_random_img(xgboost_model, X_test=X_test, test_labels= y_true, feature_extractor=vgg_mdl, le=label_enc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The random image above shows its true label and the predicted label using the XGBoost model.\n",
        "\n",
        "## Comparison Between Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: class_report_all_models\n",
        "#| tbl-cap: \"Simplified Classification Report Metrics for All Models\"\n",
        "#| warning: false\n",
        "\n",
        "# Classification Reports for all models\n",
        "model_list = [knn_model, rf_model, xgboost_model]\n",
        "comparison_df = compare_classification_reports(list_of_models=model_list, y_test=y_test, X_test=classifier_X_test)\n",
        "filtered_df = comparison_df[comparison_df['metric'].isin(['accuracy', 'macro avg', 'weighted avg'])]\n",
        "filtered_df = filtered_df.drop(columns= 'support')\n",
        "display(Markdown(filtered_df.to_markdown(index = False)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: roc_all_models\n",
        "#| fig-cap: \"ROC Curves for all Models Tested\"\n",
        "\n",
        "# ROC Curves for all models\n",
        "plot_ROC_for_all(list_of_models=model_list, y_train=y_train, y_test=y_test, X_test=classifier_X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusions\n",
        "\n",
        "One can clearly see from the ROC curves, the accuracy, precision, recall, and f1-score that the best performing model was the XGBoost model with the Random Forest coming in a close second. The KNN performed poorly and does not seem to be very well adapted to this type of application. The accuracy of both models using the pre-trained VGG16 model as a feature extractor is quite good considering that there is no dataset specific training activity on the CNN. This could be further improved, by augmenting the training image set and performing additional training on the dataset. However, this is out of the scope of this project on supervised learning techniques. The Random Forest model and XGBoost model could also benefit from a further exploration of tuning of the hyperparameters for each model. This again, was out of the scope of this project as the goal was to exam mutliple types of classification models in the context of supervised learning techniques.\n",
        "\n",
        "One aspect of this data set that is missing if we consider applying these models to the real world problem of detecting and quantifying green coffee defects is the lack of \"normal\" or \"non-defective beans\" in the dataset. This would help to better establish baseline defects vs normal performance metrics which would ensure that the model does not identify false positives in the normal beans. Furthermore, the dataset uses photos of individual beans which is not practical. It would make sense to combine a trained model with a YOLO object detection algorithm to identify individual beans in an image of multiple beans together. This would be a nice problem to solve in the context of a deep learning project.\n",
        "\n",
        "## References\n",
        "\n",
        "::: {#refs}\n",
        ":::\n",
        "\n",
        "## System Information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: system-information\n",
        "\n",
        "# Print platform info\n",
        "import platform\n",
        "print(platform.platform())\n",
        "print(platform.processor())\n",
        "print(\"python version:\", platform.python_version())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "C:\\Users\\RDClulowJa\\AppData\\Roaming\\Python\\share\\jupyter\\kernels\\python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}